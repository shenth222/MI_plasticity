# å¿«é€Ÿå¼€å§‹æŒ‡å—

> **ğŸ’¡ 2025-01-06 æ›´æ–°**ï¼šä»£ç å·²å¤§å¹…ç®€åŒ–ï¼ˆ~42% ä»£ç å‡å°‘ï¼‰ï¼Œæ€§èƒ½æå‡ã€‚è¯¦è§ [SIMPLIFICATION_NOTE.md](SIMPLIFICATION_NOTE.md)

## 5 åˆ†é’Ÿä¸Šæ‰‹

### 1ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
cd /data1/shenth/work/MI_plasticity/Activation
pip install -r requirements.txt
```

### 2ï¸âƒ£ å‡†å¤‡æ•°æ®

å°† ARC-Challenge æ•°æ®æ”¾åˆ°æŒ‡å®šç›®å½•ï¼ˆJSONL æ ¼å¼ï¼‰ï¼š

```bash
# æ•°æ®ç›®å½•ç»“æ„
/data/datasets/arc_challenge/
â””â”€â”€ test.jsonl
```

**JSONL æ ¼å¼ç¤ºä¾‹**ï¼š
```jsonl
{"id": "Mercury_7220990", "question": "Which property...", "choices": {"text": ["color", "hardness", "luster", "streak"], "label": ["A", "B", "C", "D"]}, "answerKey": "D"}
```

### 3ï¸âƒ£ å‡†å¤‡æ¨¡å‹

ä¸‹è½½ LLaMA 3.2-1B æ¨¡å‹åˆ°æœ¬åœ°ï¼š

```bash
# æ¨¡å‹ç›®å½•ç»“æ„
/data/models/llama-3.2-1b/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin (æˆ– model.safetensors)
â”œâ”€â”€ tokenizer.json
â””â”€â”€ tokenizer_config.json
```

### 4ï¸âƒ£ ä¿®æ”¹é…ç½®

ç¼–è¾‘ `configs/default.yaml`ï¼š

```yaml
model_path: "/data/models/llama-3.2-1b/"      # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
data_dir: "/data/datasets/arc_challenge/"      # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®è·¯å¾„
max_samples: 5000                              # å¤„ç†æ ·æœ¬æ•°ï¼ˆ-1 è¡¨ç¤ºå…¨éƒ¨ï¼‰
batch_size: 4                                  # æ ¹æ® GPU å†…å­˜è°ƒæ•´
dtype: "bf16"                                  # bf16/fp16/fp32
token_agg: "last"                              # last/all
```

### 5ï¸âƒ£ è¿è¡Œé‡‡é›†

```bash
# æ–¹æ³• 1: ä½¿ç”¨ bash è„šæœ¬ï¼ˆæ¨èï¼‰
bash scripts/run_arc_collect.sh

# æ–¹æ³• 2: ç›´æ¥è¿è¡Œ
python -m src.main --config configs/default.yaml

# æ–¹æ³• 3: å‘½ä»¤è¡Œè¦†ç›–å‚æ•°
python -m src.main \
    --config configs/default.yaml \
    --max_samples 1000 \
    --batch_size 2
```

### 6ï¸âƒ£ æŸ¥çœ‹ç»“æœ

```bash
# è¾“å‡ºç›®å½•
ls outputs/arc_head_activation_<timestamp>/

# åŒ…å«æ–‡ä»¶ï¼š
# - head_output_norm_mean.npy            # æ¿€æ´»æ•°æ®
# - head_resid_contrib_norm_mean.npy     # æ¿€æ´»æ•°æ®
# - head_output_norm_heatmap.png         # å¯è§†åŒ–
# - head_resid_contrib_norm_heatmap.png  # å¯è§†åŒ–
# - meta.json                            # å…ƒæ•°æ®
# - config.json                          # è¿è¡Œé…ç½®
```

---

## ğŸ”§ å¸¸ç”¨å‚æ•°è°ƒæ•´

### å†…å­˜ä¸è¶³ï¼Ÿ

```yaml
batch_size: 2          # å‡å°æ‰¹å¤§å°
max_length: 256        # å‡å°åºåˆ—é•¿åº¦
dtype: "fp16"          # ä½¿ç”¨åŠç²¾åº¦
```

### åŠ é€Ÿå¤„ç†ï¼Ÿ

```yaml
batch_size: 8          # å¢åŠ æ‰¹å¤§å°
max_samples: 1000      # å¤„ç†éƒ¨åˆ†æ ·æœ¬
device_map: "auto"     # å¤šå¡å¹¶è¡Œ
```

### æ”¹å˜èšåˆç­–ç•¥ï¼Ÿ

```yaml
token_agg: "all"       # å¯¹æ‰€æœ‰ token å¹³å‡ï¼ˆæ›´å…¨é¢ï¼‰
token_agg: "last"      # åªç”¨æœ€å tokenï¼ˆæ›´å¿«ï¼‰
```

---

## ğŸ“Š è¯»å–å’Œåˆ†æç»“æœ

```python
import numpy as np
import json
import matplotlib.pyplot as plt

# åŠ è½½æ•°æ®
head_output_norm = np.load("outputs/.../head_output_norm_mean.npy")
head_resid_norm = np.load("outputs/.../head_resid_contrib_norm_mean.npy")

# åŠ è½½å…ƒæ•°æ®
with open("outputs/.../meta.json", "r") as f:
    meta = json.load(f)

# æ•°æ®å½¢çŠ¶
print(f"Shape: {head_output_norm.shape}")  # (num_layers, num_heads)

# ç»Ÿè®¡ä¿¡æ¯
print(f"Head Output Norm range: [{head_output_norm.min():.4f}, {head_output_norm.max():.4f}]")
print(f"Processed samples: {meta['num_processed']}")

# åˆ†æç‰¹å®šå±‚
layer_0_norms = head_output_norm[0, :]
print(f"Layer 0 head norms: {layer_0_norms}")

# æ‰¾å‡ºæœ€å¼ºçš„ head
max_layer, max_head = np.unravel_index(head_output_norm.argmax(), head_output_norm.shape)
print(f"Strongest head: Layer {max_layer}, Head {max_head}")
```

---

## ğŸ§ª è¿è¡Œç¤ºä¾‹éªŒè¯

```bash
# è¿è¡Œç¤ºä¾‹è„šæœ¬éªŒè¯å®‰è£…
python example_usage.py
```

---

## âš¡ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ¨¡å—å¯¼å…¥å¤±è´¥

```bash
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
cd /data1/shenth/work/MI_plasticity/Activation

# ä½¿ç”¨ -m æ–¹å¼è¿è¡Œ
python -m src.main --config configs/default.yaml
```

### é—®é¢˜ 2: æ•°æ®åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -lh /data/datasets/arc_challenge/
cat /data/datasets/arc_challenge/test.jsonl | head -1 | python -m json.tool
```

### é—®é¢˜ 3: GPU å†…å­˜ä¸è¶³

```yaml
# ä¿®æ”¹é…ç½®
batch_size: 1          # æœ€å°æ‰¹å¤§å°
dtype: "fp16"          # åŠç²¾åº¦
max_length: 256        # çŸ­åºåˆ—
```

### é—®é¢˜ 4: Hook æ— æ³•æ•è·

```yaml
# å°è¯•ç¦ç”¨ Flash Attention
attn_implementation: null
```

---

## ğŸ“– è¿›ä¸€æ­¥é˜…è¯»

- **å®Œæ•´æ–‡æ¡£**: `README.md`
- **é¡¹ç›®æ€»ç»“**: `PROJECT_SUMMARY.md`
- **ä½¿ç”¨ç¤ºä¾‹**: `example_usage.py`
- **é…ç½®è¯´æ˜**: `configs/default.yaml`

---

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡è¿è¡Œ**: å»ºè®®å…ˆç”¨å°‘é‡æ ·æœ¬æµ‹è¯•ï¼ˆ`max_samples: 100`ï¼‰
2. **è°ƒè¯•æ¨¡å¼**: åœ¨ `src/main.py` ä¸­å°† logger level æ”¹ä¸º DEBUG
3. **ä¸­é—´ä¿å­˜**: è®¾ç½® `save_every: 100` æ¯ 100 æ­¥ä¿å­˜ä¸€æ¬¡
4. **å¤šæ¬¡å®éªŒ**: ä¿®æ”¹ `experiment_name` é¿å…è¦†ç›–

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ README.md çš„"å¸¸è§é—®é¢˜"éƒ¨åˆ†æˆ–æäº¤ Issueã€‚

