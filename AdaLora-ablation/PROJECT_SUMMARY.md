# AdaLoRA Signal-Replacement Ablation - é¡¹ç›®æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ¦‚è§ˆ

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ã€å¯ç›´æ¥è¿è¡Œçš„ AdaLoRA Signal-Replacement Ablation å®éªŒæ¡†æ¶ã€‚

**å®éªŒç›®æ ‡**: åœ¨å›ºå®š AdaLoRA è®­ç»ƒä¸é¢„ç®—è°ƒåº¦æœºåˆ¶ä¸‹ï¼Œä»…æ›¿æ¢ç”¨äº rank/budget åˆ†é…çš„ scoring signalï¼ŒéªŒè¯ importance ä¸ plasticity çš„åŒºåˆ«åŠç»„åˆæ•ˆæœã€‚

## âœ… å·²å®ç°åŠŸèƒ½

### 1. æ ¸å¿ƒæ¨¡å— (src/)

| æ¨¡å— | åŠŸèƒ½ | çŠ¶æ€ |
|-----|------|------|
| `config.py` | é…ç½®ç®¡ç†ï¼Œæ”¯æŒ CLI å’Œé…ç½®æ–‡ä»¶ | âœ“ å®Œæˆ |
| `data.py` | GLUE MNLI/RTE æ•°æ®åŠ è½½ä¸é¢„å¤„ç† | âœ“ å®Œæˆ |
| `modeling.py` | æ¨¡å‹åŠ è½½ä¸ AdaLoRA åº”ç”¨ | âœ“ å®Œæˆ |
| `signal.py` | Scoring signals è®¡ç®—ï¼ˆimportance/plasticity/comboï¼‰ | âœ“ å®Œæˆ |
| `patch_adalora.py` | PEFT RankAllocator monkeypatch | âœ“ å®Œæˆ |
| `callbacks.py` | TrainerCallbackï¼ˆè°ƒç”¨ update_and_allocateï¼‰ | âœ“ å®Œæˆ |
| `logging_utils.py` | JSONL æ—¥å¿—è®°å½•ä¸ç»“æœæ±‡æ€» | âœ“ å®Œæˆ |
| `main.py` | CLI å…¥å£ï¼ˆtrain/eval/exportï¼‰ | âœ“ å®Œæˆ |
| `plots.py` | å¯è§†åŒ–ï¼ˆrank evolution, signal heatmapï¼‰ | âœ“ å®Œæˆ |

### 2. è¿è¡Œè„šæœ¬ (scripts/)

| è„šæœ¬ | åŠŸèƒ½ | çŠ¶æ€ |
|-----|------|------|
| `run_mnli.sh` | è¿è¡Œå•ä¸ª MNLI å®éªŒ | âœ“ å®Œæˆ |
| `run_rte.sh` | è¿è¡Œå•ä¸ª RTE å®éªŒ | âœ“ å®Œæˆ |
| `run_ablation_all.sh` | ä¸€é”®è¿è¡Œæ‰€æœ‰ 4 ç§ signals | âœ“ å®Œæˆ |
| `quick_test.sh` | å¿«é€Ÿæµ‹è¯•ï¼ˆå°è§„æ¨¡é…ç½®ï¼‰ | âœ“ å®Œæˆ |
| `verify_setup.py` | ç¯å¢ƒéªŒè¯è„šæœ¬ | âœ“ å®Œæˆ |

### 3. æ–‡æ¡£

| æ–‡æ¡£ | å†…å®¹ | çŠ¶æ€ |
|-----|------|------|
| `README.md` | å®Œæ•´æ–‡æ¡£ï¼ˆå®‰è£…ã€ä½¿ç”¨ã€FAQï¼‰ | âœ“ å®Œæˆ |
| `QUICKSTART.md` | å¿«é€Ÿå¼€å§‹æŒ‡å— | âœ“ å®Œæˆ |
| `requirements.txt` | Python ä¾èµ– | âœ“ å®Œæˆ |
| `.gitignore` | Git å¿½ç•¥è§„åˆ™ | âœ“ å®Œæˆ |

## ğŸ¯ å®ç°çš„ 4 ç§ Scoring Signals

| Signal Type | è®¡ç®—å…¬å¼ | è¯´æ˜ |
|------------|---------|------|
| `baseline_adalora` | PEFT å†…ç½® | åŸç”Ÿ AdaLoRAï¼ˆä¸æ›¿æ¢ï¼‰ |
| `importance_only` | EMA(\|wÂ·grad\|) | ä¸€é˜¶ Taylor é‡è¦æ€§ |
| `plasticity_only` | EMA(\|\|grad\|\|â‚‚) | å‚æ•°å¯å¡‘æ€§ |
| `combo` | zscore(importance) + Î»Â·zscore(plasticity) | ç»„åˆ signal |

## ğŸ”§ å…³é”®æŠ€æœ¯å®ç°

### 1. Monkeypatch æœºåˆ¶

é€šè¿‡ `patch_adalora.py` å®ç°æœ€å°ä¾µå…¥å¼ patchï¼š
- ä¿å­˜åŸå§‹ `RankAllocator.update_and_allocate` æ–¹æ³•
- æ³¨å…¥å¤–éƒ¨ scoresï¼ˆæ¥è‡ª `SignalTracker`ï¼‰
- ä¸ä¿®æ”¹ AdaLoRA çš„é¢„ç®—è°ƒåº¦å’Œ rank è£å‰ªé€»è¾‘

### 2. Signal Tracking

`SignalTracker` åœ¨çº¿è®¡ç®—ï¼š
- **Importance**: åŸºäºå‚æ•°èŒƒæ•°ä¸æ¢¯åº¦èŒƒæ•°çš„ä¹˜ç§¯
- **Plasticity**: åŸºäºæ¢¯åº¦èŒƒæ•°
- **EMA å¹³æ»‘**: é¿å… signal å‰§çƒˆæ³¢åŠ¨
- **Module-level èšåˆ**: é€‚é… AdaLoRA çš„ rank åˆ†é…ç²’åº¦

### 3. Callback æœºåˆ¶

`AdaLoRACallback` ç¡®ä¿ï¼š
- ä»…åœ¨çœŸæ­£çš„ optimizer step æ—¶è°ƒç”¨ `update_and_allocate`
- å…¼å®¹ gradient accumulation
- è®°å½• rank åˆ†é…å†å²å’Œ signal scores

### 4. Budget ä¸€è‡´æ€§æ£€æŸ¥

`BudgetConsistencyCallback` ç›‘æ§ï¼š
- æ¯æ¬¡æ›´æ–°åçš„æ€» rank
- ä¸ç›®æ ‡ budget çš„åå·®
- ç”Ÿæˆä¸€è‡´æ€§æŠ¥å‘Š

## ğŸ“Š è¾“å‡ºç»“æ„

```
outputs/
â””â”€â”€ <task>/              # mnli / rte
    â””â”€â”€ <signal>/        # baseline_adalora / importance_only / ...
        â””â”€â”€ <seed>/      # 42 / 1 / 2026
            â”œâ”€â”€ metrics.jsonl           # è®­ç»ƒæŒ‡æ ‡ï¼ˆæ¯ä¸ª evalï¼‰
            â”œâ”€â”€ rank_pattern.jsonl      # Rank åˆ†é…å†å²
            â”œâ”€â”€ signal_scores.jsonl     # Signal scores å†å²
            â”œâ”€â”€ final_summary.json      # æœ€ç»ˆæ±‡æ€»
            â”œâ”€â”€ config.json             # å®éªŒé…ç½®
            â”œâ”€â”€ training.log            # å®Œæ•´æ—¥å¿—
            â”œâ”€â”€ rank_evolution.png      # Rank å˜åŒ–æ›²çº¿
            â”œâ”€â”€ signal_heatmap.png      # Signal çƒ­åŠ›å›¾
            â””â”€â”€ checkpoint-*/           # æ¨¡å‹ checkpoints
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: ç¯å¢ƒè®¾ç½®

```bash
cd /data1/shenth/work/MI_plasticity/AdaLora-ablation
pip install -r requirements.txt
python scripts/verify_setup.py
```

### Step 2: ä¿®æ”¹æ¨¡å‹è·¯å¾„

ç¼–è¾‘ `src/config.py` æˆ–ä½¿ç”¨ `--model_path` å‚æ•°ã€‚

### Step 3: è¿è¡Œå®éªŒ

```bash
# å•ä¸ªå®éªŒ
bash scripts/run_mnli.sh importance_only 42

# å®Œæ•´ ablationï¼ˆæ‰€æœ‰ 4 ç§ signalsï¼‰
bash scripts/run_ablation_all.sh mnli 42
```

### Step 4: æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹æ±‡æ€»
cat outputs/mnli/importance_only/seed42/final_summary.json | jq .

# ç”Ÿæˆå¯¹æ¯”å›¾
python src/plots.py --compare \
    --task mnli \
    --signals baseline_adalora importance_only plasticity_only combo \
    --seed 42
```

## ğŸ“ˆ é¢„æœŸå®éªŒæµç¨‹

### MNLI ä»»åŠ¡ï¼ˆå¤§è§„æ¨¡ï¼‰

```bash
# è®­ç»ƒé›†: ~393k æ ·æœ¬
# æ¨èé…ç½®:
#   - epochs: 3
#   - batch_size: 32
#   - tinit: 200
#   - tfinal: 200
#   - total steps: ~36,750

bash scripts/run_ablation_all.sh mnli 42
```

### RTE ä»»åŠ¡ï¼ˆä½èµ„æºï¼‰

```bash
# è®­ç»ƒé›†: ~2.5k æ ·æœ¬
# æ¨èé…ç½®:
#   - epochs: 5
#   - batch_size: 16
#   - tinit: 50
#   - tfinal: 100
#   - total steps: ~780

bash scripts/run_ablation_all.sh rte 42
```

### å¤š seed å®éªŒ

```bash
for seed in 42 1 2026; do
    bash scripts/run_ablation_all.sh mnli $seed
    bash scripts/run_ablation_all.sh rte $seed
done
```

## ğŸ” éªŒè¯ AdaLoRA åŠ¨æ€æ€§

### æ–¹æ³• 1: æ£€æŸ¥è®­ç»ƒæ—¥å¿—

```bash
grep "AdaLoRA Update" outputs/mnli/importance_only/seed42/training.log
```

æœŸæœ›çœ‹åˆ°ï¼š
```
[AdaLoRA Update] Step 200: Total rank=1728, Active modules=144
[AdaLoRA Update] Step 210: Total rank=1680, Active modules=144
[AdaLoRA Update] Step 220: Total rank=1632, Active modules=144
...
```

### æ–¹æ³• 2: åˆ†æ rank_pattern.jsonl

```python
import json

with open("outputs/mnli/importance_only/seed42/rank_pattern.jsonl") as f:
    for line in f:
        r = json.loads(line)
        print(f"Step {r['step']:4d}: Total rank = {r['total_rank']}")
```

### æ–¹æ³• 3: å¯è§†åŒ–

```bash
python src/plots.py --task mnli --signal importance_only --seed 42
# ç”Ÿæˆ rank_evolution.png å’Œ signal_heatmap.png
```

## âš™ï¸ é…ç½®è°ƒä¼˜å»ºè®®

### tinit / tfinal è®¾ç½®

```python
# è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°
total_steps = len(train_dataset) / batch_size / grad_accum * epochs

# å»ºè®®:
# - tinit < total_steps (ç¡®ä¿å¼€å§‹è°ƒæ•´)
# - tinit + tfinal < total_steps (ç¡®ä¿æœ‰è¶³å¤Ÿçª—å£)
# - deltaT: 10-20 (è°ƒæ•´é¢‘ç‡)

# ç¤ºä¾‹ï¼ˆMNLIï¼‰:
# total_steps â‰ˆ 392702 / 32 * 3 â‰ˆ 36750
# tinit=200, tfinal=200, deltaT=10
# â†’ åœ¨ step 200~400 ä¹‹é—´æ¯ 10 æ­¥è°ƒæ•´
```

### å†…å­˜ä¼˜åŒ–

```bash
# å¦‚æœ OOM:
--batch_size 8 \
--gradient_accumulation_steps 4 \
--fp16  # æˆ– --bf16
```

### åŠ é€Ÿè®­ç»ƒ

```bash
# ä½¿ç”¨æ›´å¤§çš„ batch size
--batch_size 64 \
--gradient_accumulation_steps 2

# å‡å°‘ logging é¢‘ç‡
--logging_steps 100
```

## ğŸ“Š ç»“æœåˆ†æç¤ºä¾‹

### å¯¼å‡ºå¯¹æ¯”è¡¨æ ¼

```python
import pandas as pd
import json

results = []
for signal in ["baseline_adalora", "importance_only", "plasticity_only", "combo"]:
    path = f"outputs/mnli/{signal}/seed42/final_summary.json"
    with open(path) as f:
        data = json.load(f)
        results.append({
            "Signal": signal,
            "Accuracy": data["metrics"]["final_eval_accuracy"],
            "Final Rank": data["rank_pattern"]["final_total_rank"],
            "Rank Reduction": data["rank_pattern"]["rank_reduction"],
        })

df = pd.DataFrame(results)
print(df.to_markdown(index=False))
```

é¢„æœŸè¾“å‡ºï¼š
```markdown
| Signal            | Accuracy | Final Rank | Rank Reduction |
|-------------------|----------|------------|----------------|
| baseline_adalora  | 0.8520   | 576        | 1152           |
| importance_only   | 0.8545   | 576        | 1152           |
| plasticity_only   | 0.8510   | 576        | 1152           |
| combo             | 0.8560   | 576        | 1152           |
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜ 1: "Target modules not found"

**åŸå› **: DeBERTa æ¨¡å—åä¸é…ç½®ä¸åŒ¹é…

**è§£å†³**:
```python
# è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰ Linear æ¨¡å—å
from transformers import AutoModel
model = AutoModel.from_pretrained("path/to/deberta-v3-base")
for name, module in model.named_modules():
    if isinstance(module, torch.nn.Linear):
        print(name)

# ä¿®æ”¹ src/config.py ä¸­çš„ target_modules
```

### é—®é¢˜ 2: Rank ä¸å˜åŒ–

**åŸå› **: tinit/tfinal è®¾ç½®ä¸å½“

**æ£€æŸ¥**:
```bash
# æŸ¥çœ‹æ€»è®­ç»ƒæ­¥æ•°
grep "max_steps" outputs/.../training.log

# ç¡®ä¿ tinit < max_steps
```

### é—®é¢˜ 3: Budget ä¸ä¸€è‡´

**åŸå› **: Patch æœªæ­£ç¡®åº”ç”¨

**è°ƒè¯•**:
```python
# æ£€æŸ¥ patch æ˜¯å¦ç”Ÿæ•ˆ
grep "Patch" outputs/.../training.log
grep "AdaLoRA Patched" outputs/.../training.log
```

## ğŸ“ ä»£ç è´¨é‡

- âœ“ æ‰€æœ‰æ¨¡å—éƒ½æœ‰æ–‡æ¡£å­—ç¬¦ä¸²
- âœ“ æ‰€æœ‰å‡½æ•°éƒ½æœ‰ç±»å‹æç¤º
- âœ“ è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜å…³é”®é€»è¾‘
- âœ“ å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
- âœ“ é…ç½®ä¸ä»£ç åˆ†ç¦»

## ğŸ“ æ‰©å±•å»ºè®®

### 1. æ·»åŠ æ›´å¤š signals

ç¼–è¾‘ `src/signal.py`ï¼Œåœ¨ `SignalTracker` ä¸­æ·»åŠ æ–°çš„ signal ç±»å‹ã€‚

### 2. æ”¯æŒæ›´å¤šä»»åŠ¡

ç¼–è¾‘ `src/data.py`ï¼Œæ·»åŠ æ–°çš„ GLUE ä»»åŠ¡æˆ–è‡ªå®šä¹‰æ•°æ®é›†ã€‚

### 3. è¶…å‚æ•°æœç´¢

ä½¿ç”¨ Optuna æˆ– Ray Tune è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ã€‚

### 4. åˆ†å¸ƒå¼è®­ç»ƒ

ä¿®æ”¹ `TrainingArguments`ï¼Œæ·»åŠ  DDP æ”¯æŒã€‚

## ğŸ“š å‚è€ƒæ–‡çŒ®

- AdaLoRA: [arXiv:2303.10512](https://arxiv.org/abs/2303.10512)
- PEFT: [https://github.com/huggingface/peft](https://github.com/huggingface/peft)
- DeBERTa: [arXiv:2006.03654](https://arxiv.org/abs/2006.03654)

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æ£€æŸ¥ï¼š
1. `README.md` - è¯¦ç»†æ–‡æ¡£
2. `QUICKSTART.md` - å¿«é€ŸæŒ‡å—
3. ä»£ç æ³¨é‡Š - å†…è”è¯´æ˜

---

**é¡¹ç›®çŠ¶æ€**: âœ… å·²å®Œæˆï¼Œå¯ç›´æ¥è¿è¡Œ

**æœ€åæ›´æ–°**: 2026-01-22
